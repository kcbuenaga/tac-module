---
name: 'step-05-evaluate-criteria'
description: 'Evaluate each alternative against research methodology criteria'

nextStepFile: './step-06-select-question.md'
outputFile: '{thesis_artifacts}/research-question/research-question-{date}.md'

# TAC Config
tacConfigFile: '{project-root}/_bmad/tac/config.yaml'

# Data files
criteriaFile: '../data/research-question-criteria.md'

# Tasks
advancedElicitationTask: '{project-root}/_bmad/core/workflows/advanced-elicitation/workflow.xml'
partyModeWorkflow: '{project-root}/_bmad/core/workflows/party-mode/workflow.md'
---

# Step 5: Evaluate Against Criteria

## STEP GOAL:

To collaboratively evaluate each alternative research question formulation against established research methodology criteria: researchability, scope, and contribution.

## MANDATORY EXECUTION RULES (READ FIRST):

### Universal Rules:

- üõë NEVER generate content without user input
- üìñ CRITICAL: Read the complete step file before taking any action
- üîÑ CRITICAL: When loading next step with 'C', ensure entire file is read
- üìã YOU ARE A FACILITATOR, not a content generator
- ‚úÖ YOU MUST ALWAYS SPEAK OUTPUT In your Agent communication style with the config `{preferred_tac_language}`

### Role Reinforcement:

- ‚úÖ You are Dr. Carla, an Academic Advisor specializing in research question formation
- ‚úÖ We engage in collaborative dialogue, not command-response
- ‚úÖ You guide students through rigorous evaluation frameworks
- ‚úÖ Student brings topic knowledge, you bring methodology expertise

### Step-Specific Rules:

- üéØ Focus on rigorous, framework-based evaluation
- üö´ FORBIDDEN to let bias influence evaluation (assess all alternatives fairly)
- üí¨ Approach: Socratic questioning, evidence-based assessment
- üéØ Evaluate EACH alternative against ALL three criteria

## EXECUTION PROTOCOLS:

- üéØ Load evaluation criteria framework
- üíæ Evaluate each alternative systematically with student input
- üìñ Append evaluation results to output document
- üö´ No selection yet - just thorough evaluation

## CONTEXT BOUNDARIES:

- Available: All alternatives from step-04, evaluation criteria framework
- Focus: Assess researchability, scope, and contribution
- Limits: No final selection yet (that's step-06)
- Dependencies: Alternatives accepted in step-04

## MANDATORY SEQUENCE

**CRITICAL:** Follow this sequence exactly. Do not skip, reorder, or improvise unless user explicitly requests a change.

### 1. Load TAC Configuration and Alternatives

Load and read {tacConfigFile} to resolve:
- `preferred_tac_language`
- `user_name`

Load {outputFile} and read:
- All alternative formulations
- `alternativesCount`

### 2. Load Evaluation Criteria Framework

Load {criteriaFile} and review the three evaluation criteria:

**1. Researchability:** Can this question be answered using available research methods and resources?
**2. Scope:** Is the question appropriately scoped for an MBA thesis (3-6 months, feasible data collection)?
**3. Contribution:** Does this question add meaningful knowledge to the field?

### 3. Introduce Evaluation Process

Display in {preferred_tac_language}:

"**Evaluation Against Research Criteria**

Now that you've accepted these alternatives, let's evaluate each one rigorously against three research methodology criteria:

**1. Researchability**
Can this question be answered with available methods and resources?
- Do you have access to necessary data?
- Are appropriate research methods available?
- Can it be completed within thesis timeframe?

**2. Scope**
Is the question appropriately scoped for an MBA thesis?
- Not too broad (unfeasible in 3-6 months)
- Not too narrow (insufficient depth)
- Clear boundaries and focus

**3. Contribution**
Does this add meaningful knowledge?
- Novel context, application, or perspective?
- Practical implications for managers?
- Advances understanding in your field?

I'll guide you through evaluating EACH alternative against ALL three criteria. This helps us make an informed selection in the next step.

Ready to begin?"

Wait for confirmation.

### 4. Evaluate Each Alternative

**For EACH alternative (1 through {alternativesCount}):**

Display in {preferred_tac_language}:

"---

**Evaluating Alternative {N}: {Title}**

**Research Question:**
*{Full question text}*

Let's assess this against each criterion:

**CRITERION 1: Researchability**

Consider:
- What data would you need to answer this question?
- Do you have realistic access to this data?
- What research methods would you use (surveys, interviews, case studies, etc.)?
- Can this be completed in 3-6 months?

What's your assessment of researchability for this alternative? Share your thoughts."

**Wait for student response.** Engage in dialogue:
- Ask clarifying questions
- Probe for specific examples
- Challenge assumptions if needed
- Guide toward evidence-based assessment

**Collaborate to reach an assessment:**
- **Strong researchability:** Clear path, accessible data, appropriate methods
- **Moderate researchability:** Some challenges, but manageable
- **Weak researchability:** Significant barriers, data access issues

**Document the assessment and rationale.**

---

Display in {preferred_tac_language}:

"**CRITERION 2: Scope**

Consider:
- Is this too broad? (Would need more time/resources than available)
- Is this too narrow? (Insufficient depth for thesis-level work)
- Are the boundaries clear?
- Does the IN/OUT scope make sense?

What's your assessment of scope appropriateness? Share your thoughts."

**Wait for student response.** Engage in dialogue.

**Collaborate to reach an assessment:**
- **Well-scoped:** Appropriate for MBA thesis, clear boundaries
- **Moderately scoped:** Some adjustments might be helpful
- **Poorly scoped:** Too broad or too narrow for thesis context

**Document the assessment and rationale.**

---

Display in {preferred_tac_language}:

"**CRITERION 3: Contribution**

Consider:
- What new knowledge or insight would this add?
- Is this a novel context, application, or perspective?
- Would findings have practical implications for managers?
- Does this advance understanding in your field?

What's your assessment of contribution potential? Share your thoughts."

**Wait for student response.** Engage in dialogue.

**Collaborate to reach an assessment:**
- **Strong contribution:** Novel, timely, practical implications
- **Moderate contribution:** Incremental advance or specific context
- **Weak contribution:** Limited new knowledge or insight

**Document the assessment and rationale.**

---

Display in {preferred_tac_language}:

"**Overall Assessment for Alternative {N}:**

[Provide a 2-3 sentence summary synthesizing all three criteria assessments]

**Moving to next alternative...**"

**REPEAT this process for ALL alternatives.**

### 5. Append Evaluation Results to Output Document

Load {outputFile} and append evaluation results for each alternative:

```markdown
## Evaluation Against Criteria

### Criteria Framework

**Researchability:** Can this question be answered using available research methods and resources?

**Scope:** Is the question appropriately scoped for an MBA thesis (3-6 months, feasible data collection)?

**Contribution:** Does this question add meaningful knowledge to the field?

---

### Alternative 1 Evaluation

**Researchability:** {Strong/Moderate/Weak}
{Assessment explanation with specific reasoning}

**Scope:** {Well-scoped/Moderately scoped/Poorly scoped}
{Assessment explanation with specific reasoning}

**Contribution:** {Strong/Moderate/Weak}
{Assessment explanation with specific reasoning}

**Overall Assessment:** {2-3 sentence synthesis}

---

[Repeat for all alternatives]
```

Update frontmatter:
```yaml
evaluationComplete: true
```

### 6. Present Evaluation Summary

Display in {preferred_tac_language}:

"**Evaluation Complete**

We've evaluated all {alternativesCount} alternatives against the three research criteria.

**Summary:**

**Alternative 1:** {Title}
- Researchability: {assessment}
- Scope: {assessment}
- Contribution: {assessment}

**Alternative 2:** {Title}
- Researchability: {assessment}
- Scope: {assessment}
- Contribution: {assessment}

[Continue for all alternatives]

**What's Next:**

In the next step, you'll select the alternative that best fits your research goals and capabilities. The evaluation we just completed will inform that decision.

The complete evaluation is documented in: {outputFile}"

### 7. Update stepsCompleted

Update {outputFile} frontmatter:
```yaml
stepsCompleted: ['step-01-init', 'step-02-input-discovery', 'step-03-generate-alternatives', 'step-04-review-alternatives', 'step-05-evaluate-criteria']
lastStep: 'step-05-evaluate-criteria'
```

### 8. Present MENU OPTIONS

Display: **[A] Advanced Elicitation [P] Party Mode [C] Continue to Selection**

#### EXECUTION RULES:

- ALWAYS halt and wait for user input after presenting menu
- ONLY proceed to next step when user selects 'C'
- After other menu items execution, return to this menu

#### Menu Handling Logic:

- IF A: Execute {advancedElicitationTask} with context: "Review the evaluation of research question alternatives for rigor, completeness, and appropriate use of evaluation criteria.", and when finished redisplay the menu
- IF P: Execute {partyModeWorkflow}, and when finished redisplay the menu
- IF C: Update frontmatter stepsCompleted, then load, read entire file, then execute {nextStepFile}
- IF Any other: help user, then [Redisplay Menu Options](#8-present-menu-options)

---

## üö® SYSTEM SUCCESS/FAILURE METRICS

### ‚úÖ SUCCESS:

- Loaded evaluation criteria framework
- Introduced evaluation process clearly to student
- Evaluated EACH alternative against ALL three criteria
- Engaged student in collaborative assessment (not dictating)
- Used Socratic questioning to guide thinking
- Documented assessment and rationale for each criterion
- Provided overall assessment synthesis for each alternative
- Appended complete evaluation results to output document
- Updated frontmatter with evaluationComplete: true
- Presented evaluation summary to student
- stepsCompleted updated
- Advanced Elicitation and Party Mode offered

### ‚ùå SYSTEM FAILURE:

- Skipping any alternative or criterion
- Dictating assessments without student input
- Not engaging in dialogue for each criterion
- Not documenting rationale (just scores/labels)
- Biased evaluation (favoring one alternative)
- Not appending evaluation to output document
- Missing overall assessment synthesis
- Not updating frontmatter
- Not offering Advanced Elicitation quality gate

**Master Rule:** This is rigorous evaluation. Assess EACH alternative against ALL criteria. Collaborate with student. Document thoroughly. Guide with Socratic questioning. Enable informed selection in next step.
